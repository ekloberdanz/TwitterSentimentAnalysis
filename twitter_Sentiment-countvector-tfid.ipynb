{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "37ahoahpfuTL",
    "outputId": "17271fc8-f1ee-418c-cb64-e49d926125a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Mon Nov 26 18:09:45 +0000 2018\", \"default_profile\": true, \"default_profile_image\": true, \"friends_count\": 2, \"id\": 1067118225744371712, \"id_str\": \"1067118225744371712\", \"name\": \"EliskaKloberdanz\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_image_url_https\": \"https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"EliskaKloberda1\"}\n"
     ]
    }
   ],
   "source": [
    "##!pip install python-twitter\n",
    "import twitter\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = \"4QlG7dBQ1UeHAXyk1pC6n7LTm\"\n",
    "API_KEY_SECRET = \"td6zhDHTI795WKXGYjXBJUwba9xCyxZ3o73VYro9XtLrQD30UZ\"\n",
    "ACCESS_TOKEN = \"1067118225744371712-8rjdKc3f2rFNf7FXczj5T3X1W6yfu4\"\n",
    "ACCESS_TOKEN_SECRET = \"Hw1A7nii1S2JAh0hMgkR6xZB1IddC1KAgJBPI5OaoQnSv\"\n",
    "\n",
    "# initialize api instance\n",
    "twitter_api = twitter.Api(consumer_key=API_KEY,\n",
    "                  consumer_secret=API_KEY_SECRET,\n",
    "                  access_token_key=ACCESS_TOKEN,\n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# test authentication\n",
    "print(twitter_api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Twitter for any key word for which you want to analyze sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5NCW4Y-fzwi"
   },
   "outputs": [],
   "source": [
    "# serach tweets by key words\n",
    "def buildTestSet(search_keyword):\n",
    "    text = []\n",
    "    try:\n",
    "        tweets_fetched = twitter_api.GetSearch(search_keyword, count=100)\n",
    "        print(\"Fetched \" + str(len(tweets_fetched)) + \" tweets for the term \" + search_keyword)\n",
    "        for status in tweets_fetched:\n",
    "            text.append(status.text)\n",
    "        return pd.DataFrame({'tweet_text': text})\n",
    "        #return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]\n",
    "    except:\n",
    "        print(\"Unfortunately, something went wrong..\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "6Hu11Wdhf2Gr",
    "outputId": "75e7208f-73b5-4439-d4eb-344c91d85fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search keyword: oil\n",
      "Fetched 100 tweets for the term oil\n",
      "                                          tweet_text\n",
      "0  The President of Tanzania was suspicious of th...\n",
      "1  Speaker Pelosi supports push for taxpayer bail...\n",
      "2  Palm oil is in pretty much everything. This is...\n",
      "3  RT @steve_hanke: .@Pemex is killing, not savin...\n"
     ]
    }
   ],
   "source": [
    "search_term = input(\"Enter a search keyword: \")\n",
    "testDataSet = buildTestSet(search_term)\n",
    "\n",
    "print(testDataSet[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train Set or Upload if Train Set Exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time \n",
    "\n",
    "def downloadTweetText(corpusFile):\n",
    "    corpus = pd.read_csv(corpusFile)\n",
    "    corpus.columns = ['', 'topic', 'label', 'tweet_id']\n",
    "    corpus = corpus.drop(corpus.columns[0], axis=1)\n",
    "    rate_limit=180\n",
    "    sleep_time=900/180\n",
    "    \n",
    "    training_tweets_text =[]\n",
    "\n",
    "    for tweet in corpus['tweet_id']:\n",
    "        try:\n",
    "            status = twitter_api.GetStatus(tweet)\n",
    "            print(\"Tweet fetched\" + status.text)\n",
    "            training_tweets_text.append(status.text)\n",
    "            #time.sleep(sleep_time)\n",
    "        except: \n",
    "            training_tweets_text.append('NaN')\n",
    "            continue\n",
    "    print(\"Finished scraping\")\n",
    "    return training_tweets_text\n",
    "\n",
    "if path.exists(\"trainingData.csv\"):\n",
    "    # upload train set\n",
    "    trainingData = pd.read_csv('trainingData.csv')\n",
    "else:\n",
    "    # create train set\n",
    "    corpusFile = 'labeled_corpus.csv'\n",
    "    trainingDataTweetText = downloadTweetText(corpusFile)\n",
    "    trainingData = pd.read_csv(corpusFile)\n",
    "    trainingData['tweet_text'] = trainingDataTweetText\n",
    "    corpus.columns = ['', 'topic', 'label', 'tweet_id', 'tweet_text']\n",
    "    trainingData.to_csv('trainingData.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1    253\n",
       " 0    248\n",
       " 1    116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NaNs\n",
    "trainingData = trainingData[trainingData['tweet_text'].isnull() == False]\n",
    "\n",
    "# Unique Labels\n",
    "trainingData['label'].unique()\n",
    "\n",
    "# Encode Labels\n",
    "trainingData.loc[trainingData.label == 'neutral', 'label'] = 0\n",
    "trainingData.loc[trainingData.label == 'irrelevant', 'label'] = 2\n",
    "trainingData.loc[trainingData.label == 'positive','label'] = 1\n",
    "trainingData.loc[trainingData.label == 'negative', 'label'] = -1\n",
    "\n",
    "# Check dirstibution of labels\n",
    "trainingData.groupby('label').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dataset labels distribuition')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset label distribution\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "target_cnt = Counter(trainingData.label)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.264028e+17</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263972e+17</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263797e+17</td>\n",
       "      <td>The 16 strangest things Siri has said so far. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263777e+17</td>\n",
       "      <td>Great up close &amp; personal event @Apple tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263738e+17</td>\n",
       "      <td>From which companies do you experience the bes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  label      tweet_id  \\\n",
       "1  apple      1  1.264028e+17   \n",
       "2  apple      1  1.263972e+17   \n",
       "5  apple      1  1.263797e+17   \n",
       "6  apple      1  1.263777e+17   \n",
       "7  apple      1  1.263738e+17   \n",
       "\n",
       "                                          tweet_text  \n",
       "1  Hilarious @youtube video - guy does a duet wit...  \n",
       "2  @RIM you made it too easy for me to switch to ...  \n",
       "5  The 16 strangest things Siri has said so far. ...  \n",
       "6  Great up close & personal event @Apple tonight...  \n",
       "7  From which companies do you experience the bes...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "\n",
    "def preprocess_Text(data):\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    for row in data.index:\n",
    "        text = data.loc[row, 'tweet_text']\n",
    "        text = text.lower()\n",
    "        text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w in words and w.isalpha()) #remove non-english words\n",
    "        text = re.sub('<[^<]+?>', '', text) #remove html tags\n",
    "        text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) #remove links\n",
    "        text = text.strip('=')\n",
    "        text = text.split(\" \") \n",
    "        text = [w for w in text if w not in nltk.corpus.stopwords.words('english')]\n",
    "        lem = nltk.stem.WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(i) for i in text]\n",
    "        text = ' '.join(str(e) for e in text)\n",
    "        data.loc[row,'tweet_text'] = text #replace description in place in the dataframe\n",
    "        row += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the training set so that it is balanced\n",
    "\n",
    "smallest_Category = trainingData.groupby('label').size().min()\n",
    "\n",
    "data_0 = trainingData.loc[trainingData['label'] == 0].head(smallest_Category)\n",
    "data_1 = trainingData.loc[trainingData['label'] == 1].head(smallest_Category)\n",
    "data_neg_1 = trainingData.loc[trainingData['label'] == -1].head(smallest_Category)\n",
    "\n",
    "balanced_Data = pd.concat([data_0, data_1, data_neg_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1.264175e+17</td>\n",
       "      <td>would watched apple jihad adobe flash consider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1.264156e+17</td>\n",
       "      <td>hey apple brand new state art new phone come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1.264147e+17</td>\n",
       "      <td>apple record quarter bunch professional aka di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1.264100e+17</td>\n",
       "      <td>interesting read war b w apple latter agree la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1.264080e+17</td>\n",
       "      <td>apple earnings call even apple need new releas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic  label      tweet_id  \\\n",
       "567  apple      0  1.264175e+17   \n",
       "569  apple      0  1.264156e+17   \n",
       "570  apple      0  1.264147e+17   \n",
       "572  apple      0  1.264100e+17   \n",
       "573  apple      0  1.264080e+17   \n",
       "\n",
       "                                            tweet_text  \n",
       "567  would watched apple jihad adobe flash consider...  \n",
       "569       hey apple brand new state art new phone come  \n",
       "570  apple record quarter bunch professional aka di...  \n",
       "572  interesting read war b w apple latter agree la...  \n",
       "573  apple earnings call even apple need new releas...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = preprocess_Text(balanced_Data)\n",
    "trainingData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>president suspicious testing trick investigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speaker push taxpayer corporate morning propos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>palm oil pretty much everything cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>killing saving slash oil production despite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>difference h oil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text\n",
       "0     president suspicious testing trick investigate\n",
       "1  speaker push taxpayer corporate morning propos...\n",
       "2              palm oil pretty much everything cheap\n",
       "3        killing saving slash oil production despite\n",
       "4                                   difference h oil"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingData = preprocess_Text(testDataSet)\n",
    "testingData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # Count vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "\n",
    "list_of_vectorizors = [CountVectorizer(), TfidfVectorizer()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data intro train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into traning and testing\n",
    "split_ratio = 0.7\n",
    "total_number_of_datapoints = len(trainingData.index)\n",
    "train_number_of_datapoints = int(total_number_of_datapoints * split_ratio)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "trainingData = shuffle(trainingData)\n",
    "\n",
    "train_set = trainingData.iloc[:train_number_of_datapoints, :]\n",
    "test_set = trainingData.iloc[train_number_of_datapoints:, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(clf, vectorizer):\n",
    "    #  Train the classifier\n",
    "    vectorizer.fit_transform(list(trainingData['tweet_text']))\n",
    "    vectors_train = vectorizer.transform(list(train_set['tweet_text']))\n",
    "    clf.fit(vectors_train, train_set['label'].values)\n",
    "\n",
    "    # Get the test vectors\n",
    "    vectors_test = vectorizer.transform(list(test_set['tweet_text']))\n",
    "\n",
    "    # Predict and score the vectors\n",
    "    from sklearn import metrics\n",
    "    pred = clf.predict(vectors_test)\n",
    "    acc_score = metrics.accuracy_score( test_set['label'].values, pred)\n",
    "    f1_score = metrics.f1_score( test_set['label'].values, pred, average='macro')\n",
    "#     print('\\nModel type: {}'.format(clf))\n",
    "#     print('Vectorization type: {}'.format(vectorizer))\n",
    "#     print('Total accuracy classification score: {}'.format(acc_score))\n",
    "#     print('Total F1 classification score: {}'.format(f1_score))\n",
    "#     print('--------------------------------------------------------------------------------')\n",
    "    return clf, acc_score\n",
    "\n",
    "# Build the classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "list_of_models = [MultinomialNB(alpha=.01), tree.DecisionTreeClassifier(), RandomForestClassifier(), \n",
    "                  AdaBoostClassifier(), LogisticRegression(), \n",
    "                  KNeighborsClassifier(), SVC(), MLPClassifier()]\n",
    "\n",
    "results = pd.DataFrame(columns = ['model_type', 'vectorization_type', 'accuracy'])\n",
    "\n",
    "results_acc = []\n",
    "results_vect = []\n",
    "results_models = []\n",
    "\n",
    "\n",
    "best_acc = 0\n",
    "for model_type in list_of_models:\n",
    "    for vectorizer in list_of_vectorizors:\n",
    "        clf = model(model_type, vectorizer)[0]\n",
    "        acc = model(model_type, vectorizer)[1]\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_model = clf\n",
    "            best_acc = acc\n",
    "        \n",
    "        results_acc.append(model(model_type, vectorizer)[1])\n",
    "        results_vect.append(vectorizer)\n",
    "        results_models.append(model_type)\n",
    "\n",
    "data = {'model_type': results_models, 'vectorization_type': results_vect, 'accuracy': results_acc}\n",
    "results = pd.DataFrame(data, columns = ['model_type', 'vectorization_type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for different model types and vectorization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>vectorization_type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.561905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.561905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=0.01, class_prior=None, fi...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.504762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB(alpha=0.01, class_prior=None, fi...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.438095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.390476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.295238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.295238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_type  \\\n",
       "9   LogisticRegression(C=1.0, class_weight=None, d...   \n",
       "11  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "2   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "8   LogisticRegression(C=1.0, class_weight=None, d...   \n",
       "0   MultinomialNB(alpha=0.01, class_prior=None, fi...   \n",
       "5   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "14  MLPClassifier(activation='relu', alpha=0.0001,...   \n",
       "15  MLPClassifier(activation='relu', alpha=0.0001,...   \n",
       "4   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "1   MultinomialNB(alpha=0.01, class_prior=None, fi...   \n",
       "7   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "6   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "3   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "12  SVC(C=1.0, cache_size=200, class_weight=None, ...   \n",
       "13  SVC(C=1.0, cache_size=200, class_weight=None, ...   \n",
       "\n",
       "                                   vectorization_type  accuracy  \n",
       "9   TfidfVectorizer(analyzer='word', binary=False,...  0.561905  \n",
       "11  TfidfVectorizer(analyzer='word', binary=False,...  0.561905  \n",
       "2   CountVectorizer(analyzer='word', binary=False,...  0.542857  \n",
       "8   CountVectorizer(analyzer='word', binary=False,...  0.533333  \n",
       "0   CountVectorizer(analyzer='word', binary=False,...  0.514286  \n",
       "5   TfidfVectorizer(analyzer='word', binary=False,...  0.514286  \n",
       "14  CountVectorizer(analyzer='word', binary=False,...  0.514286  \n",
       "15  TfidfVectorizer(analyzer='word', binary=False,...  0.514286  \n",
       "4   CountVectorizer(analyzer='word', binary=False,...  0.504762  \n",
       "1   TfidfVectorizer(analyzer='word', binary=False,...  0.485714  \n",
       "7   TfidfVectorizer(analyzer='word', binary=False,...  0.466667  \n",
       "6   CountVectorizer(analyzer='word', binary=False,...  0.438095  \n",
       "3   TfidfVectorizer(analyzer='word', binary=False,...  0.400000  \n",
       "10  CountVectorizer(analyzer='word', binary=False,...  0.390476  \n",
       "12  CountVectorizer(analyzer='word', binary=False,...  0.295238  \n",
       "13  TfidfVectorizer(analyzer='word', binary=False,...  0.295238  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test vectors\n",
    "vectors_test = vectorizer.transform(list(testDataSet['tweet_text']))\n",
    "pred = best_model.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataSet['label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode Labels\n",
    "testDataSet.loc[testDataSet.label == 0, 'label'] = 'neutral'\n",
    "testDataSet.loc[testDataSet.label == 2, 'label'] = 'irrelevant'\n",
    "testDataSet.loc[testDataSet.label == 1,'label'] = 'positive'\n",
    "testDataSet.loc[testDataSet.label == -1, 'label'] = 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>president suspicious testing trick investigate</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speaker push taxpayer corporate morning propos...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>palm oil pretty much everything cheap</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>killing saving slash oil production despite</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>difference h oil</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tweet got thinking remember oil bust someone m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     label\n",
       "0     president suspicious testing trick investigate  negative\n",
       "1  speaker push taxpayer corporate morning propos...  negative\n",
       "2              palm oil pretty much everything cheap  negative\n",
       "3        killing saving slash oil production despite  negative\n",
       "4                                   difference h oil  negative\n",
       "5  tweet got thinking remember oil bust someone m...  positive"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataSet.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
