{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "37ahoahpfuTL",
    "outputId": "17271fc8-f1ee-418c-cb64-e49d926125a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Mon Nov 26 18:09:45 +0000 2018\", \"default_profile\": true, \"default_profile_image\": true, \"friends_count\": 2, \"id\": 1067118225744371712, \"id_str\": \"1067118225744371712\", \"name\": \"EliskaKloberdanz\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_image_url_https\": \"https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"EliskaKloberda1\"}\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-twitter\n",
    "import twitter\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = \"4QlG7dBQ1UeHAXyk1pC6n7LTm\"\n",
    "API_KEY_SECRET = \"td6zhDHTI795WKXGYjXBJUwba9xCyxZ3o73VYro9XtLrQD30UZ\"\n",
    "ACCESS_TOKEN = \"1067118225744371712-8rjdKc3f2rFNf7FXczj5T3X1W6yfu4\"\n",
    "ACCESS_TOKEN_SECRET = \"Hw1A7nii1S2JAh0hMgkR6xZB1IddC1KAgJBPI5OaoQnSv\"\n",
    "\n",
    "# initialize api instance\n",
    "twitter_api = twitter.Api(consumer_key=API_KEY,\n",
    "                  consumer_secret=API_KEY_SECRET,\n",
    "                  access_token_key=ACCESS_TOKEN,\n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# test authentication\n",
    "print(twitter_api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Twitter for any key word for which you want to analyze sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5NCW4Y-fzwi"
   },
   "outputs": [],
   "source": [
    "# serach tweets by key words\n",
    "def buildTestSet(search_keyword):\n",
    "    text = []\n",
    "    try:\n",
    "        tweets_fetched = twitter_api.GetSearch(search_keyword, count=100)\n",
    "        print(\"Fetched \" + str(len(tweets_fetched)) + \" tweets for the term \" + search_keyword)\n",
    "        for status in tweets_fetched:\n",
    "            text.append(status.text)\n",
    "        return pd.DataFrame({'tweet_text': text})\n",
    "        #return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]\n",
    "    except:\n",
    "        print(\"Unfortunately, something went wrong..\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "6Hu11Wdhf2Gr",
    "outputId": "75e7208f-73b5-4439-d4eb-344c91d85fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search keyword: oil\n",
      "Fetched 100 tweets for the term oil\n",
      "                                          tweet_text\n",
      "0  India is the only country in the world where G...\n",
      "1  Argentina has circulated a proposal to set $45...\n",
      "2  The leaders of the Green Party and the Bloc Qu...\n",
      "3  RT @SmilyRose1994: He Trying To Anal Fingering...\n"
     ]
    }
   ],
   "source": [
    "search_term = input(\"Enter a search keyword: \")\n",
    "testDataSet = buildTestSet(search_term)\n",
    "\n",
    "print(testDataSet[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('labeled_corpus.csv')\n",
    "corpus.columns = ['', 'topic', 'label', 'tweet_id']\n",
    "corpus = corpus.drop(corpus.columns[0], axis=1)\n",
    "corpus.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lw1CZ-Nsf_41"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time \n",
    "def downloadTweetText(corpusFile):\n",
    "    corpus = pd.read_csv(corpusFile)\n",
    "    corpus.columns = ['', 'topic', 'label', 'tweet_id']\n",
    "    corpus = corpus.drop(corpus.columns[0], axis=1)\n",
    "    rate_limit=180\n",
    "    sleep_time=900/180\n",
    "    \n",
    "    training_tweets_text =[]\n",
    "\n",
    "    for tweet in corpus['tweet_id']:\n",
    "        try:\n",
    "            status = twitter_api.GetStatus(tweet)\n",
    "            print(\"Tweet fetched\" + status.text)\n",
    "            training_tweets_text.append(status.text)\n",
    "            #time.sleep(sleep_time)\n",
    "        except: \n",
    "            training_tweets_text.append('NaN')\n",
    "            continue\n",
    "    print(\"Finished scraping\")\n",
    "    return training_tweets_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "Tr1Ejn4igA-u",
    "outputId": "2010c1a2-410a-4576-8a9f-69158ae9fde7"
   },
   "outputs": [],
   "source": [
    "corpusFile = 'labeled_corpus.csv'\n",
    "trainingDataTweetText = downloadTweetText(corpusFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = list(set(trainingDataTweetText))\n",
    "trainingData = pd.read_csv(corpusFile)\n",
    "trainingData['tweet_text'] = trainingDataTweetText\n",
    "corpus.columns = ['', 'topic', 'label', 'tweet_id', 'tweet_text']\n",
    "trainingData.to_csv('trainingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = pd.read_csv('trainingData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1    253\n",
       " 0    248\n",
       " 1    116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NaNs\n",
    "trainingData = trainingData[trainingData['tweet_text'].isnull() == False]\n",
    "\n",
    "# Unique Labels\n",
    "trainingData['label'].unique()\n",
    "\n",
    "# Encode Labels\n",
    "trainingData.loc[trainingData.label == 'neutral', 'label'] = 0\n",
    "trainingData.loc[trainingData.label == 'irrelevant', 'label'] = 2\n",
    "trainingData.loc[trainingData.label == 'positive','label'] = 1\n",
    "trainingData.loc[trainingData.label == 'negative', 'label'] = -1\n",
    "\n",
    "# Check dirstibution of labels\n",
    "trainingData.groupby('label').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.264028e+17</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263972e+17</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263797e+17</td>\n",
       "      <td>The 16 strangest things Siri has said so far. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263777e+17</td>\n",
       "      <td>Great up close &amp; personal event @Apple tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263738e+17</td>\n",
       "      <td>From which companies do you experience the bes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  label      tweet_id  \\\n",
       "1  apple      1  1.264028e+17   \n",
       "2  apple      1  1.263972e+17   \n",
       "5  apple      1  1.263797e+17   \n",
       "6  apple      1  1.263777e+17   \n",
       "7  apple      1  1.263738e+17   \n",
       "\n",
       "                                          tweet_text  \n",
       "1  Hilarious @youtube video - guy does a duet wit...  \n",
       "2  @RIM you made it too easy for me to switch to ...  \n",
       "5  The 16 strangest things Siri has said so far. ...  \n",
       "6  Great up close & personal event @Apple tonight...  \n",
       "7  From which companies do you experience the bes...  "
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_Text(data):\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    for row in data.index:\n",
    "        text = data.loc[row, 'tweet_text']\n",
    "        text = text.lower()\n",
    "        text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w in words and w.isalpha()) #remove non-english words\n",
    "        text = re.sub('<[^<]+?>', '', text) #remove html tags\n",
    "        text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) #remove links\n",
    "        text = text.strip('=')\n",
    "        text = text.split(\" \") \n",
    "        text = [w for w in text if w not in nltk.corpus.stopwords.words('english')]\n",
    "        lem = nltk.stem.WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(i) for i in text]\n",
    "        text = ' '.join(str(e) for e in text)\n",
    "        data.loc[row,'tweet_text'] = text #replace description in place in the dataframe\n",
    "        row += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.264028e+17</td>\n",
       "      <td>hilarious video guy duet apple pretty much lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263972e+17</td>\n",
       "      <td>rim made easy switch apple see ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263797e+17</td>\n",
       "      <td>said far glad apple gave sense humor via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263777e+17</td>\n",
       "      <td>great close personal event apple tonight regen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263738e+17</td>\n",
       "      <td>experience best customer service aside apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  label      tweet_id  \\\n",
       "1  apple      1  1.264028e+17   \n",
       "2  apple      1  1.263972e+17   \n",
       "5  apple      1  1.263797e+17   \n",
       "6  apple      1  1.263777e+17   \n",
       "7  apple      1  1.263738e+17   \n",
       "\n",
       "                                          tweet_text  \n",
       "1  hilarious video guy duet apple pretty much lov...  \n",
       "2                  rim made easy switch apple see ya  \n",
       "5           said far glad apple gave sense humor via  \n",
       "6  great close personal event apple tonight regen...  \n",
       "7       experience best customer service aside apple  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = preprocess_Text(trainingData)\n",
    "trainingData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country world increasing price petrol diesel d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proposal set per barrel price oil bid keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green party bloc calling government stop suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trying anal fingering oil massage watch full v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text\n",
       "0  country world increasing price petrol diesel d...\n",
       "1         proposal set per barrel price oil bid keep\n",
       "2  green party bloc calling government stop suppo...\n",
       "3  trying anal fingering oil massage watch full v...\n",
       "4                                                   "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingData = preprocess_Text(testDataSet)\n",
    "testingData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy classification score: 0.6290322580645161\n",
      "Total F1 classification score: 0.6034058656575213\n"
     ]
    }
   ],
   "source": [
    "# Create our vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(list(train_set['tweet_text']))\n",
    "\n",
    "# Build the classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data intro train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into traning and testing\n",
    "split_ratio = 0.7\n",
    "total_number_of_datapoints = len(trainingData.index)\n",
    "train_number_of_datapoints = int(total_number_of_datapoints * split_ratio)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "trainingData = shuffle(trainingData)\n",
    "\n",
    "train_set = trainingData.iloc[:train_number_of_datapoints, :]\n",
    "test_set = trainingData.iloc[train_number_of_datapoints:, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train the classifier\n",
    "clf.fit(vectors, train_set['label'].values)\n",
    "\n",
    "# Get the test vectors\n",
    "vectors_test = vectorizer.transform(list(test_set['tweet_text']))\n",
    "\n",
    "# Predict and score the vectors\n",
    "from sklearn import metrics\n",
    "pred = clf.predict(vectors_test)\n",
    "acc_score = metrics.accuracy_score( test_set['label'].values, pred)\n",
    "f1_score = metrics.f1_score( test_set['label'].values, pred, average='macro')\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score))\n",
    "print('Total F1 classification score: {}'.format(f1_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test vectors\n",
    "vectors_test = vectorizer.transform(list(testDataSet['tweet_text']))\n",
    "pred = clf.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataSet['label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode Labels\n",
    "testDataSet.loc[testDataSet.label == 0, 'label'] = 'neutral'\n",
    "testDataSet.loc[testDataSet.label == 2, 'label'] = 'irrelevant'\n",
    "testDataSet.loc[testDataSet.label == 1,'label'] = 'positive'\n",
    "testDataSet.loc[testDataSet.label == -1, 'label'] = 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country world increasing price petrol diesel d...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proposal set per barrel price oil bid keep</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green party bloc calling government stop suppo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trying anal fingering oil massage watch full v...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>smart really pinnacle bygone era utopian born ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     label\n",
       "0  country world increasing price petrol diesel d...   neutral\n",
       "1         proposal set per barrel price oil bid keep  positive\n",
       "2  green party bloc calling government stop suppo...  negative\n",
       "3  trying anal fingering oil massage watch full v...   neutral\n",
       "4                                                     negative\n",
       "5  smart really pinnacle bygone era utopian born ...  negative"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataSet.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
