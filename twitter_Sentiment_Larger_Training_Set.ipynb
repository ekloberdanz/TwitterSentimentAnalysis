{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "37ahoahpfuTL",
    "outputId": "17271fc8-f1ee-418c-cb64-e49d926125a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Mon Nov 26 18:09:45 +0000 2018\", \"default_profile\": true, \"default_profile_image\": true, \"friends_count\": 2, \"id\": 1067118225744371712, \"id_str\": \"1067118225744371712\", \"name\": \"EliskaKloberdanz\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_image_url_https\": \"https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"EliskaKloberda1\"}\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-twitter\n",
    "import twitter\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = \"4QlG7dBQ1UeHAXyk1pC6n7LTm\"\n",
    "API_KEY_SECRET = \"td6zhDHTI795WKXGYjXBJUwba9xCyxZ3o73VYro9XtLrQD30UZ\"\n",
    "ACCESS_TOKEN = \"1067118225744371712-8rjdKc3f2rFNf7FXczj5T3X1W6yfu4\"\n",
    "ACCESS_TOKEN_SECRET = \"Hw1A7nii1S2JAh0hMgkR6xZB1IddC1KAgJBPI5OaoQnSv\"\n",
    "\n",
    "# initialize api instance\n",
    "twitter_api = twitter.Api(consumer_key=API_KEY,\n",
    "                  consumer_secret=API_KEY_SECRET,\n",
    "                  access_token_key=ACCESS_TOKEN,\n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# test authentication\n",
    "print(twitter_api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Twitter for any key word for which you want to analyze sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5NCW4Y-fzwi"
   },
   "outputs": [],
   "source": [
    "# serach tweets by key words\n",
    "def buildTestSet(search_keyword):\n",
    "    text = []\n",
    "    try:\n",
    "        tweets_fetched = twitter_api.GetSearch(search_keyword, count=100)\n",
    "        print(\"Fetched \" + str(len(tweets_fetched)) + \" tweets for the term \" + search_keyword)\n",
    "        for status in tweets_fetched:\n",
    "            text.append(status.text)\n",
    "        return pd.DataFrame({'tweet_text': text})\n",
    "        #return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]\n",
    "    except:\n",
    "        print(\"Unfortunately, something went wrong..\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "6Hu11Wdhf2Gr",
    "outputId": "75e7208f-73b5-4439-d4eb-344c91d85fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search keyword: trump\n",
      "Fetched 100 tweets for the term trump\n",
      "                                          tweet_text\n",
      "0  If Trump can obliterate the liberal activist j...\n",
      "1  This is stunning to watch: 60 Minutes details ...\n",
      "2  Strange that the media isn‚Äôt talking about thi...\n",
      "3  RT @gregolear: Last night we were playing Cele...\n"
     ]
    }
   ],
   "source": [
    "search_term = input(\"Enter a search keyword: \")\n",
    "testDataSet = buildTestSet(search_term)\n",
    "\n",
    "print(testDataSet[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Trump can obliterate the liberal activist j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is stunning to watch: 60 Minutes details ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strange that the media isn‚Äôt talking about thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @gregolear: Last night we were playing Cele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realDonaldTrump Do we have a national plan on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @Rickster_75: FLASHBACK: WATCH Barack Obama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @bourgeoisalien: Beyond any shadow of a dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@realDonaldTrump @WashTimes I love you Preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @Amy_Siskind: Trump sent more than 120 twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @InGoodSpirets: @SenSchumer Let's make this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @mattyglesias: It‚Äôs surprising* that given ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT @stopalready23: @politvidchannel In the mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @nprpolitics: President Trump said last wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT @crismartinj: ¬øC√≥mo? ¬øQue al final va a ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @6af1s: \"I fought Bush's wars; I fought Oba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT @thedailybeast: EXCLUSIVE: A Democratic gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @TeaPainUSA: Every time Trump tweets, MAGA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@realDonaldTrump Your kidding me right? For th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT @ShimonPro: In conversations this weekend, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RT @carlosmartinezr: La foto para ilustrar al ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RT @maddenifico: It's really a shame that #60M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RT @Amy_Siskind: Trump staff scared to go to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT @ianbremmer: Masks and self-quarantine woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@matthewamiller @JoeBiden You will need a plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RT @Jolus2505: Don Al Trump, casi asegurando l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@Monalis13083792 Donaaald trump üòèüòè\\n#KehGayiSo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RT @pdjf1: PAMELA KARLAN FACT- CHECKER AND CHE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RT @mmpadellan: I don't want to hear any more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>@realDonaldTrump tRUMP is the first ‚Äúpresident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>RT @ju_tmjbrasil: Pois √©. Trump chegou no Obam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>RT @andylassner: Donald Trump has turned Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>@Juju_Senpai0 @2Samossa Jte bloque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RT @TaraSetmayer: Ummmm....any one else find t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RT @KrauseForIowa: With viruses it is hard to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>@MikeCarlton01 At a superficial level, perhaps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RT @MajorPatriot: \"What you are seeing is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>RT @EaterSouls: Trump dismantles environmental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>RT @DanWTwitmo6: @realDonaldTrump Trump: \"the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>RT @whstancil: Beside the point, but I do find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>RT @Lrihendry: President Trump is a marketing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RT @MiguelTorresZ83: Uuufff, estaba leyendo el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>RT @SenSchumer: It's May 10th, and President T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>RT @GA_peach3102: FLASHBACK:Obama pushes some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RT @thejtlewis: Obama: ‚ÄúI led a scandal-free a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>@M_Fall_ ca j‚Äôavais un peu compris mais genre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>RT @GreggJarrett: Ending Michael Flynn prosecu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RT @lara_putnam: It was an honor getting to wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>RT @JaimIMSSSmuper: #ObamaGate\\n\\nDe nuevo, el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>In similar vein; what are your views on the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>RT @neal_katyal: This Tuesday, the Supreme Cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>@TeamTrump @realDonaldTrump And some people of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RT @100_Disable_vet: Trump slow response to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RT @SethAbramson: 5/ The Trump-Saudi, Trump-UA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RT @CAGoldenBear: @joncoopertweets Oh yeah. Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text\n",
       "0   If Trump can obliterate the liberal activist j...\n",
       "1   This is stunning to watch: 60 Minutes details ...\n",
       "2   Strange that the media isn‚Äôt talking about thi...\n",
       "3   RT @gregolear: Last night we were playing Cele...\n",
       "4   @realDonaldTrump Do we have a national plan on...\n",
       "5   RT @Rickster_75: FLASHBACK: WATCH Barack Obama...\n",
       "6   RT @bourgeoisalien: Beyond any shadow of a dou...\n",
       "7   @realDonaldTrump @WashTimes I love you Preside...\n",
       "8   RT @Amy_Siskind: Trump sent more than 120 twee...\n",
       "9   RT @InGoodSpirets: @SenSchumer Let's make this...\n",
       "10  RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...\n",
       "11  RT @mattyglesias: It‚Äôs surprising* that given ...\n",
       "12  RT @stopalready23: @politvidchannel In the mea...\n",
       "13  RT @nprpolitics: President Trump said last wee...\n",
       "14  RT @crismartinj: ¬øC√≥mo? ¬øQue al final va a ser...\n",
       "15  RT @6af1s: \"I fought Bush's wars; I fought Oba...\n",
       "16  RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...\n",
       "17  RT @thedailybeast: EXCLUSIVE: A Democratic gro...\n",
       "18  RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...\n",
       "19  RT @TeaPainUSA: Every time Trump tweets, MAGA ...\n",
       "20  @realDonaldTrump Your kidding me right? For th...\n",
       "21  RT @ShimonPro: In conversations this weekend, ...\n",
       "22  RT @carlosmartinezr: La foto para ilustrar al ...\n",
       "23  RT @maddenifico: It's really a shame that #60M...\n",
       "24  RT @Amy_Siskind: Trump staff scared to go to w...\n",
       "25  RT @ianbremmer: Masks and self-quarantine woul...\n",
       "26  @matthewamiller @JoeBiden You will need a plan...\n",
       "27  RT @Jolus2505: Don Al Trump, casi asegurando l...\n",
       "28  @Monalis13083792 Donaaald trump üòèüòè\\n#KehGayiSo...\n",
       "29  RT @pdjf1: PAMELA KARLAN FACT- CHECKER AND CHE...\n",
       "..                                                ...\n",
       "70  RT @mmpadellan: I don't want to hear any more ...\n",
       "71  @realDonaldTrump tRUMP is the first ‚Äúpresident...\n",
       "72  RT @ju_tmjbrasil: Pois √©. Trump chegou no Obam...\n",
       "73  RT @andylassner: Donald Trump has turned Ameri...\n",
       "74                 @Juju_Senpai0 @2Samossa Jte bloque\n",
       "75  RT @TaraSetmayer: Ummmm....any one else find t...\n",
       "76  RT @KrauseForIowa: With viruses it is hard to ...\n",
       "77  @MikeCarlton01 At a superficial level, perhaps...\n",
       "78  RT @MajorPatriot: \"What you are seeing is the ...\n",
       "79  RT @EaterSouls: Trump dismantles environmental...\n",
       "80  RT @DanWTwitmo6: @realDonaldTrump Trump: \"the ...\n",
       "81  RT @whstancil: Beside the point, but I do find...\n",
       "82  RT @Lrihendry: President Trump is a marketing ...\n",
       "83  RT @MiguelTorresZ83: Uuufff, estaba leyendo el...\n",
       "84  RT @SenSchumer: It's May 10th, and President T...\n",
       "85  RT @GA_peach3102: FLASHBACK:Obama pushes some ...\n",
       "86  RT @thejtlewis: Obama: ‚ÄúI led a scandal-free a...\n",
       "87  @M_Fall_ ca j‚Äôavais un peu compris mais genre ...\n",
       "88  RT @GreggJarrett: Ending Michael Flynn prosecu...\n",
       "89  RT @lara_putnam: It was an honor getting to wo...\n",
       "90  RT @JaimIMSSSmuper: #ObamaGate\\n\\nDe nuevo, el...\n",
       "91  In similar vein; what are your views on the to...\n",
       "92  RT @neal_katyal: This Tuesday, the Supreme Cou...\n",
       "93  RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...\n",
       "94  @TeamTrump @realDonaldTrump And some people of...\n",
       "95  RT @100_Disable_vet: Trump slow response to th...\n",
       "96  RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...\n",
       "97  RT @SethAbramson: 5/ The Trump-Saudi, Trump-UA...\n",
       "98  RT @CAGoldenBear: @joncoopertweets Oh yeah. Tr...\n",
       "99  RT @realDonaldTrump: .@WashTimes  ‚ÄúFBI Went Ro...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mybirch</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    tweet_id                          date      flag           user  \\\n",
       "0      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4      0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "5      0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY        mybirch   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   \n",
       "5                                        Need a hug   "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('labeled_training_set.csv', encoding='latin-1')\n",
    "corpus.columns = ['label', 'tweet_id', 'date', 'flag', 'user', 'tweet_text']\n",
    "corpus.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5072\n",
       "4    4928\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NaNs\n",
    "trainingData = corpus.copy()\n",
    "trainingData = trainingData[trainingData['tweet_text'].isnull() == False]\n",
    "\n",
    "# Unique Labels\n",
    "trainingData['label'].unique()\n",
    "\n",
    "# Downsample data\n",
    "from sklearn.utils import shuffle\n",
    "trainingData = shuffle(trainingData)\n",
    "trainingData = trainingData.iloc[:10000, :]\n",
    "\n",
    "# Check dirstibution of labels\n",
    "trainingData.groupby('label').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    text = text.lower()\n",
    "    text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w in words and w.isalpha()) #remove non-english words\n",
    "    text = re.sub('<[^<]+?>', '', text) #remove html tags\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) #remove links\n",
    "    text = text.strip('=')\n",
    "    text = text.split(\" \") \n",
    "    text = [w for w in text if w not in nltk.corpus.stopwords.words('english')]\n",
    "    lem = nltk.stem.WordNetLemmatizer()\n",
    "    text = [lem.lemmatize(i) for i in text]\n",
    "    text = ' '.join(str(e) for e in text)\n",
    "    return text\n",
    "\n",
    "# multithreaded data pre-processing\n",
    "import multiprocessing as mp\n",
    "with mp.Pool() as pool:\n",
    "    tokens = pool.map(preprocess_text, trainingData.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.tweet_text = tokens\n",
    "trainingData.to_csv('trainingData_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump obliterate liberal activist judiciary se...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stunning watch political campaign went tu</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strange medium talking couple ago great would ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last night celebrity year old legitimately fin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>national plan trump virus yet</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     label\n",
       "0  trump obliterate liberal activist judiciary se...  positive\n",
       "1          stunning watch political campaign went tu  negative\n",
       "2  strange medium talking couple ago great would ...  negative\n",
       "3  last night celebrity year old legitimately fin...  positive\n",
       "4                      national plan trump virus yet  positive"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mp.Pool() as pool:\n",
    "    tokens_test = pool.map(preprocess_text, testDataSet.tweet_text)\n",
    "testDataSet.tweet_text = tokens_test\n",
    "testDataSet.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # Count vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "\n",
    "list_of_vectorizors = [CountVectorizer(), TfidfVectorizer()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data intro train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into traning and testing\n",
    "split_ratio = 0.7\n",
    "total_number_of_datapoints = len(trainingData.index)\n",
    "train_number_of_datapoints = int(total_number_of_datapoints * split_ratio)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "trainingData = shuffle(trainingData)\n",
    "\n",
    "train_set = trainingData.iloc[:train_number_of_datapoints, :]\n",
    "test_set = trainingData.iloc[train_number_of_datapoints:, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eliska/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>vectorization_type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.722000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.710667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.693667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.687333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB(alpha=0.01, class_prior=None, fi...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB(alpha=0.01, class_prior=None, fi...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.671667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.666333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.663667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.658667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.632333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.615333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_type  \\\n",
       "9   LogisticRegression(C=1.0, class_weight=None, d...   \n",
       "8   LogisticRegression(C=1.0, class_weight=None, d...   \n",
       "5   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "4   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "0   MultinomialNB(alpha=0.01, class_prior=None, fi...   \n",
       "1   MultinomialNB(alpha=0.01, class_prior=None, fi...   \n",
       "2   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14  MLPClassifier(activation='relu', alpha=0.0001,...   \n",
       "15  MLPClassifier(activation='relu', alpha=0.0001,...   \n",
       "3   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "6   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "7   (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "10  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "11  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "12  SVC(C=1.0, cache_size=200, class_weight=None, ...   \n",
       "13  SVC(C=1.0, cache_size=200, class_weight=None, ...   \n",
       "\n",
       "                                   vectorization_type  accuracy  \n",
       "9   TfidfVectorizer(analyzer='word', binary=False,...  0.722000  \n",
       "8   CountVectorizer(analyzer='word', binary=False,...  0.710667  \n",
       "5   TfidfVectorizer(analyzer='word', binary=False,...  0.693667  \n",
       "4   CountVectorizer(analyzer='word', binary=False,...  0.687333  \n",
       "0   CountVectorizer(analyzer='word', binary=False,...  0.682000  \n",
       "1   TfidfVectorizer(analyzer='word', binary=False,...  0.671667  \n",
       "2   CountVectorizer(analyzer='word', binary=False,...  0.666333  \n",
       "14  CountVectorizer(analyzer='word', binary=False,...  0.663667  \n",
       "15  TfidfVectorizer(analyzer='word', binary=False,...  0.658667  \n",
       "3   TfidfVectorizer(analyzer='word', binary=False,...  0.649000  \n",
       "6   CountVectorizer(analyzer='word', binary=False,...  0.646667  \n",
       "7   TfidfVectorizer(analyzer='word', binary=False,...  0.632333  \n",
       "10  CountVectorizer(analyzer='word', binary=False,...  0.615333  \n",
       "11  TfidfVectorizer(analyzer='word', binary=False,...  0.554000  \n",
       "12  CountVectorizer(analyzer='word', binary=False,...  0.506000  \n",
       "13  TfidfVectorizer(analyzer='word', binary=False,...  0.506000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def model(clf, vectorizer):\n",
    "    #  Train the classifier\n",
    "    vectorizer.fit_transform(list(trainingData['tweet_text']))\n",
    "    vectors_train = vectorizer.transform(list(train_set['tweet_text']))\n",
    "    clf.fit(vectors_train, train_set['label'].values)\n",
    "\n",
    "    # Get the test vectors\n",
    "    vectors_test = vectorizer.transform(list(test_set['tweet_text']))\n",
    "\n",
    "    # Predict and score the vectors\n",
    "    from sklearn import metrics\n",
    "    pred = clf.predict(vectors_test)\n",
    "    acc_score = metrics.accuracy_score( test_set['label'].values, pred)\n",
    "    f1_score = metrics.f1_score( test_set['label'].values, pred, average='macro')\n",
    "#     print('\\nModel type: {}'.format(clf))\n",
    "#     print('Vectorization type: {}'.format(vectorizer))\n",
    "#     print('Total accuracy classification score: {}'.format(acc_score))\n",
    "#     print('Total F1 classification score: {}'.format(f1_score))\n",
    "#     print('--------------------------------------------------------------------------------')\n",
    "    return clf, acc_score\n",
    "\n",
    "list_of_models = [MultinomialNB(alpha=.01), tree.DecisionTreeClassifier(), RandomForestClassifier(), \n",
    "                  AdaBoostClassifier(), LogisticRegression(), \n",
    "                  KNeighborsClassifier(), SVC(), MLPClassifier()]\n",
    "\n",
    "results = pd.DataFrame(columns = ['model_type', 'vectorization_type', 'accuracy'])\n",
    "\n",
    "results_acc = []\n",
    "results_vect = []\n",
    "results_models = []\n",
    "\n",
    "\n",
    "best_acc = 0\n",
    "for model_type in list_of_models:\n",
    "    for vectorizer in list_of_vectorizors:\n",
    "        clf = model(model_type, vectorizer)[0]\n",
    "        acc = model(model_type, vectorizer)[1]\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_model = clf\n",
    "            best_acc = acc\n",
    "        \n",
    "        results_acc.append(model(model_type, vectorizer)[1])\n",
    "        results_vect.append(vectorizer)\n",
    "        results_models.append(model_type)\n",
    "\n",
    "data = {'model_type': results_models, 'vectorization_type': results_vect, 'accuracy': results_acc}\n",
    "results = pd.DataFrame(data, columns = ['model_type', 'vectorization_type', 'accuracy'])\n",
    "results.sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test vectors\n",
    "vectors_test = vectorizer.transform(list(testDataSet['tweet_text']))\n",
    "pred = best_model.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataSet['label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode Labels\n",
    "testDataSet.loc[testDataSet.label == 0, 'label'] = 'negative'\n",
    "testDataSet.loc[testDataSet.label == 4,'label'] = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump obliterate liberal activist judiciary se...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stunning watch political campaign went tu</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strange medium talking couple ago great would ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last night celebrity year old legitimately fin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>national plan trump virus yet</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>watch push working together trump oval office ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     label\n",
       "0  trump obliterate liberal activist judiciary se...  positive\n",
       "1          stunning watch political campaign went tu  negative\n",
       "2  strange medium talking couple ago great would ...  positive\n",
       "3  last night celebrity year old legitimately fin...  negative\n",
       "4                      national plan trump virus yet  negative\n",
       "5  watch push working together trump oval office ...  negative"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataSet.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataSet.to_csv('testDataSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
